# DOGZILLA

## Abstract

Quadruped robots are four-legged animal-like robots that are talented in traversing challenging environments. However, conventional control method does not work satisfactorily in handling terrain tasks, which limits the development of legged robotâ€™s traversability. A learning-based method named Deep Reinforcement Learning (Deep RL) have been deployed successfully in various research and application of quadrupedal robots. However, the control policy acquired by Deep RL method often lacks versatility on different robots. This project utilizes a light-weight quadruped robot, DOGZILLA, to accomplish terrain traversing tasks based on {Deep RL method}. The training process follows a Sim-to-Real process. The result shows that the robot dog acquired basic traversability through intricate terrains such as stairs, dynamic platform and cluttered surface, indicating the successful validation of versatility of Deep RL methods and the promising traversability of light-weight quadruped systems. 

![image](https://github.com/JLCucumber/DOGZILLA/assets/72130595/cf6bb815-9a91-4b35-974e-00a747db1011)

---

## Project Plan
The current plan for my project is:

**Start-up**
  - Define an **accurate** research topic and keep refine it afterwards
  - Tools and platforms set-up: GitHub repository, OverLeaf, Linux & ROS ...
  - Build robots and conduct basic tests
  - LITERATURE REVIEW

Then the whole process is divided into three parts: **Literature Review, Implementation, and Writing**
**Literature Review** section includes a core reading part, a supplementary reading part, and two writing parts. In core reading, I'll read through papers that are most relevant to my topic, such as. Once the review is basically finished, I'll write them into my dissertation. In supplementary reading part, which takes place during the December holiday, I'll read extra necessary papers as a supplement to better facilitate my project. After that, I'll refine my literature review section.

**Implementation** section mainly includes three parts: 1) Robot dog set-up and basic tests, 2) Development and tests in simulation environments and 3) Development and tests in real-world environments. In set-up and basic tests period, I'll construct the robot dog, configure its working environments and develop a series of function tests that will support the afterward coding (such as obstacle avoidance, following objects and etc.). In simulation part, the goal is to train the robot dog to acquire satisfying control policies in challenging terrains. Both Reinforcement Learning method and traditional control methods are used in this section. Besides, several simulated terrains are needed for training. In real-world testings, I need to deploy the best control policy onto the physical robot dog, and test its performance in different real environment. 

**Writing** section goes on throughout the whole project. In semester 1, the introduction, literature review and requirement \& methodology parts are mostly focused. Semester 2 is the time to get the rest of sections done, including implementation, result, analysis and conclusion. Besides, overall refinement and presentation is also done in this section after the whole body is completed.


![Project Plan 1](https://github.com/JLCucumber/DOGZILLA/assets/72130595/cfa07ad7-b07e-4698-a379-7a882a48f0b6)

## Log/Joural
* [Week 2](./logs/week2.md)
* [Week 3](./logs/week3.md)
* [Week 4](./logs/Week4.md)
* [Week_5](./logs/Week5.md)
* [Week 6](./logs/Week6.md)
* [Week 7](./logs/Week7/Week7.md)
* [Week 8](./logs/Week8/Week8.md)
* [Week 9](./logs/Week9/Week9.md)

